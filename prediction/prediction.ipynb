{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rn-kay99/Notebooks/blob/main/prediction/prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIdSlpcH1x-D"
      },
      "source": [
        "#Hands-On Exercise: Predictive Monitoring\n",
        "\n",
        "In this exercise, you will take up the real-world event log of a process to manage road traffic fines, introduced already in an earlier exercise. The following text gives some further details on this log, quoted from Mannhardt et al. (Computing, 2016):\n",
        "\n",
        "_The road traffic fine management process is supported by an information system that records data about its operations in a PostgresSQL database. The database snapshot used here was taken in June 2013. We exported the event log to a CSV format and converted it to the XES format [â€¦]. From the analysis of the event log, we noticed that cases are usually completed within 6 months, including those cases ending with a referral to credit collection. For the analysis, we want to consider only finished cases. As a heuristic to ensure this, we filtered out any case that started after June 2012. Since the relevant laws and procedures are rather stable over the past years, the last year of the event log should show the same behavior as in previous years. The resulting event log contains 145,800 event traces, which were recorded between January 2000 and June 2012._\n",
        "\n",
        "The event log comes with this notebook but can also be downloaded (XES format, please unzip) [here](https://data.4tu.nl/repository/uuid:270fd440-1057-4fb9-89a9-b699b47990f5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fjx9Qtu51x-O"
      },
      "outputs": [],
      "source": [
        "# show plots in better quality\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "# import data from google drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# direct data upload\n",
        "#from google.colab import files\n",
        "#files.upload()\n",
        "\n",
        "# fetch the data file\n",
        "! wget -O traffic.xes.gz https://github.com/matthiasweidlich/promi_course/blob/master/prediction/traffic.xes.gz?raw=true\n",
        "\n",
        "# unzip the data file\n",
        "! gzip -d traffic.xes.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdFbRQvy1x-T"
      },
      "source": [
        "## Import Event Log\n",
        "The following method imports the log file and returns it in a list structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ao9_foav1x-V"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as et\n",
        "\n",
        "def load_xes(file, event_filter=[]):\n",
        "    log = []\n",
        "\n",
        "    tree = et.parse(file)\n",
        "    data = tree.getroot()\n",
        "\n",
        "    # find all traces\n",
        "    traces = data.findall('{http://www.xes-standard.org/}trace')\n",
        "\n",
        "    for t in traces:\n",
        "        trace_id = None\n",
        "\n",
        "        # get trace id\n",
        "        for a in t.findall('{http://www.xes-standard.org/}string'):\n",
        "            if a.attrib['key'] == 'concept:name':\n",
        "                trace_id = a.attrib['value']\n",
        "\n",
        "        events = []\n",
        "        # events\n",
        "        for event in t.iter('{http://www.xes-standard.org/}event'):\n",
        "\n",
        "            e = {'name': None, 'timestamp': None, 'resource': None, 'transition': None,\n",
        "                 'amount': None, 'dismissal': None, 'vehicleClass': None, 'totalPaymentAmount': None,\n",
        "                 'article': None, 'points': None, 'expense': None, 'notificationType': None, 'lastSent': None}\n",
        "\n",
        "            for a in event:\n",
        "                key = a.attrib['key']\n",
        "                if ':' in key:\n",
        "                    key = key.split(':')[1]\n",
        "                e[key] = a.attrib['value']\n",
        "\n",
        "            if e['name'] in event_filter or len(event_filter) == 0:\n",
        "                events.append(e)\n",
        "\n",
        "        # add trace to log\n",
        "        if len(events) > 0:\n",
        "            log.append({'trace_id': trace_id, 'events': events})\n",
        "    return log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH6mbTsA1x-X"
      },
      "source": [
        "Now import the given log and compute the trace variants of the log along with their frequencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EA_Hdlh1x-Y"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "log_file = './traffic.xes'\n",
        "log = load_xes(log_file)\n",
        "\n",
        "print('Load log with %s traces.' %len(log))\n",
        "\n",
        "trace_variants = {}\n",
        "for trace in log:\n",
        "    events = []\n",
        "    for event in trace['events']:\n",
        "        events.append(event['name'])\n",
        "    trace_variants[tuple(events)] = trace_variants.get(tuple(events), 0) + 1\n",
        "\n",
        "# print the two most frequent variants\n",
        "trace_variants_sorted_by_freq = sorted(trace_variants.items(), key=lambda kv: kv[1], reverse=True)\n",
        "pprint(trace_variants_sorted_by_freq[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyN1Qegl1x-d"
      },
      "source": [
        "## Task: Feature and Label Extraction\n",
        "The following function takes the event log as input and needs to derive the feature vectors per trace and the label per trace for one of the LTL queries given in the exercise sheet. Complete the respective code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_-pRU8n1x-f"
      },
      "outputs": [],
      "source": [
        "def extract_features_and_labels(log, feature_keys):\n",
        "    labels = []\n",
        "    features = []\n",
        "\n",
        "    for trace in log:\n",
        "        trace_truth_value = False\n",
        "\n",
        "        ############################################\n",
        "        # Your code here to\n",
        "        #  - identify whether the trace satisfies the query\n",
        "        #    (Take a simplistic approach. Do not derive a\n",
        "        #     Kripke structure, but simply scan the trace\n",
        "        #     sequentially to decide whether a constraint\n",
        "        #     of the form G(x => F(y)) is satisfied)\n",
        "        #  - collect all the features from each trace,\n",
        "        #    such that features is a list of lists, e.g.,\n",
        "        #    [[\"A\", 2],[\"B\", 8], [\"A\", 6]] for three traces\n",
        "        #    that have two features each\n",
        "        ############################################\n",
        "\n",
        "        if trace_truth_value:\n",
        "            labels.append(1)\n",
        "        else:\n",
        "            labels.append(0)\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "# The features to consider\n",
        "feature_keys = ['resource', 'amount', 'dismissal', 'vehicleClass', 'totalPaymentAmount', 'article', 'points', 'expense', 'notificationType', 'lastSent']\n",
        "\n",
        "# Call the method to extract features and labels\n",
        "features, labels = extract_features_and_labels(log, feature_keys)\n",
        "\n",
        "# Do some post-processing to encode categorical variables\n",
        "import pandas as pd\n",
        "features_tmp = pd.DataFrame(features, columns=feature_keys)\n",
        "# Those are the numeric variables\n",
        "features_df = features_tmp[['amount', 'totalPaymentAmount', 'article', 'points', 'expense']]\n",
        "# Apply a one-hot-encoding for the categorical variables\n",
        "features_df = pd.concat((features_df, pd.get_dummies(features_tmp.resource, prefix=\"resource\")), axis=1)\n",
        "features_df = pd.concat((features_df, pd.get_dummies(features_tmp.dismissal, prefix=\"dismissal\")), axis=1)\n",
        "features_df = pd.concat((features_df, pd.get_dummies(features_tmp.vehicleClass, prefix=\"vehicleClass\")), axis=1)\n",
        "features_df = pd.concat((features_df, pd.get_dummies(features_tmp.notificationType, prefix=\"notificationType\")), axis=1)\n",
        "features_df = pd.concat((features_df, pd.get_dummies(features_tmp.lastSent, prefix=\"lastSent\")), axis=1)\n",
        "\n",
        "pprint(features_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2faWYVg1x-i"
      },
      "source": [
        "## Learn the Prediction Model\n",
        "The code below learns a decision tree from the extracted features and labels. Explore the resulting tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUd6lUtn1x-k"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "import graphviz\n",
        "\n",
        "# Learn a decision tree\n",
        "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
        "if not features_df.empty:\n",
        "  clf = clf.fit(features_df, labels)\n",
        "\n",
        "  # Render the obtained decision tree\n",
        "  dot_data = tree.export_graphviz(\n",
        "    clf, out_file=None, feature_names=list(features_df), class_names=['true', 'false'],\n",
        "    filled=True, rounded=True, special_characters=True)\n",
        "  graph = graphviz.Source(dot_data)\n",
        "  display(graph)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "prediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}