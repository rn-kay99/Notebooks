{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rn-kay99/Notebooks/blob/main/prediction/prediction_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIdSlpcH1x-D"
      },
      "source": [
        "#Hands-On Exercise: Predictive Monitoring\n",
        "\n",
        "In this exercise, you will take up the real-world event log of a process to manage road traffic fines, introduced already in an earlier exercise. The following text gives some further details on this log, quoted from Mannhardt et al. (Computing, 2016):\n",
        "\n",
        "_The road traffic fine management process is supported by an information system that records data about its operations in a PostgresSQL database. The database snapshot used here was taken in June 2013. We exported the event log to a CSV format and converted it to the XES format […]. From the analysis of the event log, we noticed that cases are usually completed within 6 months, including those cases ending with a referral to credit collection. For the analysis, we want to consider only finished cases. As a heuristic to ensure this, we filtered out any case that started after June 2012. Since the relevant laws and procedures are rather stable over the past years, the last year of the event log should show the same behavior as in previous years. The resulting event log contains 145,800 event traces, which were recorded between January 2000 and June 2012._\n",
        "\n",
        "The event log comes with this notebook but can also be downloaded (XES format, please unzip) [here](https://data.4tu.nl/repository/uuid:270fd440-1057-4fb9-89a9-b699b47990f5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fjx9Qtu51x-O"
      },
      "outputs": [],
      "source": [
        "# show plots in better quality\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "# import data from google drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# direct data upload\n",
        "#from google.colab import files\n",
        "#files.upload()\n",
        "\n",
        "# fetch the data file\n",
        "! wget -O traffic.xes.gz https://github.com/matthiasweidlich/promi_course/blob/master/prediction/traffic.xes.gz?raw=true\n",
        "\n",
        "# unzip the data file\n",
        "! gzip -d traffic.xes.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdFbRQvy1x-T"
      },
      "source": [
        "## Import Event Log\n",
        "The following method imports the log file and returns it in a list structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ao9_foav1x-V"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as et\n",
        "\n",
        "def load_xes(file, event_filter=[]):\n",
        "    log = []\n",
        "\n",
        "    tree = et.parse(file)\n",
        "    data = tree.getroot()\n",
        "\n",
        "    # find all traces\n",
        "    traces = data.findall('{http://www.xes-standard.org/}trace')\n",
        "\n",
        "    for t in traces:\n",
        "        trace_id = None\n",
        "\n",
        "        # get trace id\n",
        "        for a in t.findall('{http://www.xes-standard.org/}string'):\n",
        "            if a.attrib['key'] == 'concept:name':\n",
        "                trace_id = a.attrib['value']\n",
        "\n",
        "        events = []\n",
        "        # events\n",
        "        for event in t.iter('{http://www.xes-standard.org/}event'):\n",
        "\n",
        "            e = {'name': None, 'timestamp': None, 'resource': None, 'transition': None,\n",
        "                 'amount': None, 'dismissal': None, 'vehicleClass': None, 'totalPaymentAmount': None,\n",
        "                 'article': None, 'points': None, 'expense': None, 'notificationType': None, 'lastSent': None}\n",
        "\n",
        "            for a in event:\n",
        "                key = a.attrib['key']\n",
        "                if ':' in key:\n",
        "                    key = key.split(':')[1]\n",
        "                e[key] = a.attrib['value']\n",
        "\n",
        "            if e['name'] in event_filter or len(event_filter) == 0:\n",
        "                events.append(e)\n",
        "\n",
        "        # add trace to log\n",
        "        if len(events) > 0:\n",
        "            log.append({'trace_id': trace_id, 'events': events})\n",
        "    return log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH6mbTsA1x-X"
      },
      "source": [
        "Now import the given log and compute the trace variants of the log along with their frequencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_EA_Hdlh1x-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c670599a-54c1-4011-a9f5-d6bccbdb4116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load log with 150370 traces.\n",
            "[(('Create Fine',\n",
            "   'Send Fine',\n",
            "   'Insert Fine Notification',\n",
            "   'Add penalty',\n",
            "   'Send for Credit Collection'),\n",
            "  56482),\n",
            " (('Create Fine', 'Payment'), 46371)]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "log_file = './traffic.xes'\n",
        "log = load_xes(log_file)\n",
        "\n",
        "print('Load log with %s traces.' %len(log))\n",
        "\n",
        "trace_variants = {}\n",
        "for trace in log:\n",
        "    events = []\n",
        "    for event in trace['events']:\n",
        "        events.append(event['name'])\n",
        "    trace_variants[tuple(events)] = trace_variants.get(tuple(events), 0) + 1\n",
        "\n",
        "# print the two most frequent variants\n",
        "trace_variants_sorted_by_freq = sorted(trace_variants.items(), key=lambda kv: kv[1], reverse=True)\n",
        "pprint(trace_variants_sorted_by_freq[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyN1Qegl1x-d"
      },
      "source": [
        "## Task: Feature and Label Extraction\n",
        "The following function takes the event log as input and needs to derive the feature vectors per trace and the label per trace for one of the LTL queries given in the exercise sheet. Complete the respective code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "o_-pRU8n1x-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f64f2f3-041d-46cb-9b95-2c1eb00a290f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       amount totalPaymentAmount article points expense\n",
            "0        None               None    None   None    None\n",
            "1        None               None    None   None    None\n",
            "2        None               None    None   None    None\n",
            "3        None               None    None   None    None\n",
            "4        None               None    None   None    None\n",
            "...       ...                ...     ...    ...     ...\n",
            "150365   None               None    None   None    None\n",
            "150366   None               None    None   None    None\n",
            "150367   None               None    None   None    None\n",
            "150368   None               None    None   None    None\n",
            "150369   None               None    None   None    None\n",
            "\n",
            "[150370 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "def extract_features_and_labels(log, feature_keys):\n",
        "    labels = []\n",
        "    features = []\n",
        "\n",
        "    for trace in log:\n",
        "        trace_truth_value = True\n",
        "        has_appeal_to_judge = False\n",
        "        trace_features = []\n",
        "\n",
        "        ############################################\n",
        "        # Your code here to\n",
        "        #  - identify whether the trace satisfies the query\n",
        "        #    (Take a simplistic approach. Do not derive a\n",
        "        #     Kripke structure, but simply scan the trace\n",
        "        #     sequentially to decide whether a constraint\n",
        "        #     of the form G(x => F(y)) is satisfied)\n",
        "        #  - collect all the features from each trace,\n",
        "        #    such that features is a list of lists, e.g.,\n",
        "        #    [[\"A\", 2],[\"B\", 8], [\"A\", 6]] for three traces\n",
        "        #    that have two features each\n",
        "        ############################################\n",
        "\n",
        "        for event in trace['events']:\n",
        "          # set label\n",
        "          if event['name'] == 'Appeal to Judge':\n",
        "            trace_truth_value = False\n",
        "            has_appeal_to_judge = True\n",
        "          elif event['name'] == 'Add penalty' and has_appeal_to_judge:\n",
        "            trace_truth_value = True\n",
        "\n",
        "            # set feature vector\n",
        "            for feature in feature_keys:\n",
        "              if feature in event:\n",
        "                trace_features.append(event[feature])\n",
        "\n",
        "        features.append(trace_features)\n",
        "\n",
        "\n",
        "        if trace_truth_value:\n",
        "            labels.append(1)\n",
        "        else:\n",
        "            labels.append(0)\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "# The features to consider\n",
        "feature_keys = ['resource', 'amount', 'dismissal', 'vehicleClass', 'totalPaymentAmount', 'article', 'points', 'expense', 'notificationType', 'lastSent']\n",
        "\n",
        "# Call the method to extract features and labels\n",
        "features, labels = extract_features_and_labels(log, feature_keys)\n",
        "\n",
        "# Do some post-processing to encode categorical variables\n",
        "import pandas as pd\n",
        "features_tmp = pd.DataFrame(features, columns=feature_keys)\n",
        "# Those are the numeric variables\n",
        "features_df = features_tmp[['amount', 'totalPaymentAmount', 'article', 'points', 'expense']]\n",
        "# Apply a one-hot-encoding for the categorical variables\n",
        "features_df = pd.concat((features_df, pd.get_dummies(features_tmp.resource, prefix=\"resource\")), axis=1)\n",
        "features_df = pd.concat((features_df, pd.get_dummies(features_tmp.dismissal, prefix=\"dismissal\")), axis=1)\n",
        "features_df = pd.concat((features_df, pd.get_dummies(features_tmp.vehicleClass, prefix=\"vehicleClass\")), axis=1)\n",
        "features_df = pd.concat((features_df, pd.get_dummies(features_tmp.notificationType, prefix=\"notificationType\")), axis=1)\n",
        "features_df = pd.concat((features_df, pd.get_dummies(features_tmp.lastSent, prefix=\"lastSent\")), axis=1)\n",
        "\n",
        "pprint(features_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2faWYVg1x-i"
      },
      "source": [
        "## Learn the Prediction Model\n",
        "The code below learns a decision tree from the extracted features and labels. Explore the resulting tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PUd6lUtn1x-k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "9aa6344b-8291-4e42-b051-2f5be1dac144"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"284pt\" height=\"195pt\"\n viewBox=\"0.00 0.00 283.50 195.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 191)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-191 279.5,-191 279.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M189.5,-187C189.5,-187 66.5,-187 66.5,-187 60.5,-187 54.5,-181 54.5,-175 54.5,-175 54.5,-116 54.5,-116 54.5,-110 60.5,-104 66.5,-104 66.5,-104 189.5,-104 189.5,-104 195.5,-104 201.5,-110 201.5,-116 201.5,-116 201.5,-175 201.5,-175 201.5,-181 195.5,-187 189.5,-187\"/>\n<text text-anchor=\"start\" x=\"90\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">amount ≤ inf</text>\n<text text-anchor=\"start\" x=\"92.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.003</text>\n<text text-anchor=\"start\" x=\"72\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 150370</text>\n<text text-anchor=\"start\" x=\"62.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [258, 150112]</text>\n<text text-anchor=\"start\" x=\"90\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = false</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M98,-68C98,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 98,0 98,0 104,0 110,-6 110,-12 110,-12 110,-56 110,-56 110,-62 104,-68 98,-68\"/>\n<text text-anchor=\"start\" x=\"27\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"10\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 297</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 297]</text>\n<text text-anchor=\"start\" x=\"17\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = false</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M100.82,-103.73C94.92,-94.88 88.67,-85.51 82.75,-76.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"85.66,-74.68 77.2,-68.3 79.83,-78.56 85.66,-74.68\"/>\n<text text-anchor=\"middle\" x=\"72.3\" y=\"-89.11\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M263.5,-68C263.5,-68 140.5,-68 140.5,-68 134.5,-68 128.5,-62 128.5,-56 128.5,-56 128.5,-12 128.5,-12 128.5,-6 134.5,0 140.5,0 140.5,0 263.5,0 263.5,0 269.5,0 275.5,-6 275.5,-12 275.5,-12 275.5,-56 275.5,-56 275.5,-62 269.5,-68 263.5,-68\"/>\n<text text-anchor=\"start\" x=\"166.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.003</text>\n<text text-anchor=\"start\" x=\"146\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 150073</text>\n<text text-anchor=\"start\" x=\"136.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [258, 149815]</text>\n<text text-anchor=\"start\" x=\"164\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = false</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M155.55,-103.73C161.53,-94.88 167.87,-85.51 173.87,-76.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"176.8,-78.54 179.5,-68.3 171,-74.63 176.8,-78.54\"/>\n<text text-anchor=\"middle\" x=\"184.24\" y=\"-89.14\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x786899336fd0>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn import tree\n",
        "import graphviz\n",
        "\n",
        "# Learn a decision tree\n",
        "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
        "if not features_df.empty:\n",
        "  clf = clf.fit(features_df, labels)\n",
        "\n",
        "  # Render the obtained decision tree\n",
        "  dot_data = tree.export_graphviz(\n",
        "    clf, out_file=None, feature_names=list(features_df), class_names=['true', 'false'],\n",
        "    filled=True, rounded=True, special_characters=True)\n",
        "  graph = graphviz.Source(dot_data)\n",
        "  display(graph)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "prediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}